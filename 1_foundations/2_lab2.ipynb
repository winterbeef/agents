{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key not set (and this is optional)\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach solving the ethical dilemmas presented by the deployment of artificial intelligence in surveillance, balancing safety, privacy, and civil liberties?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Addressing the ethical dilemmas posed by deploying artificial intelligence (AI) in surveillance requires a nuanced approach that balances safety, privacy, and civil liberties. Here are some steps to consider:\n",
       "\n",
       "1. **Stakeholder Engagement**:\n",
       "   - Involve a diverse group of stakeholders, including policymakers, ethicists, technologists, civil rights advocates, and the communities affected by surveillance.\n",
       "   - Conduct public consultations to gather input from citizens about their concerns and expectations regarding surveillance technologies.\n",
       "\n",
       "2. **Establish Ethical Guidelines**:\n",
       "   - Develop a set of ethical guidelines for the deployment and use of AI in surveillance, based on principles such as fairness, accountability, transparency, and respect for privacy.\n",
       "   - Ensure these guidelines are adaptable to different contexts and scales of surveillance applications.\n",
       "\n",
       "3. **Legal Frameworks**:\n",
       "   - Advocate for laws and regulations that govern the use of AI in surveillance, ensuring they protect civil liberties and privacy rights while allowing for legitimate security needs.\n",
       "   - Implement checks and balances, including oversight bodies responsible for monitoring surveillance practices and the use of AI.\n",
       "\n",
       "4. **Transparency and Accountability**:\n",
       "   - Mandate transparency in how AI surveillance systems operate, including data collection methods, algorithms used, and decision-making processes.\n",
       "   - Establish mechanisms for accountability, ensuring that there are channels for redress when violations of privacy or civil liberties occur.\n",
       "\n",
       "5. **Data Protection and Minimization**:\n",
       "   - Prioritize data protection measures, ensuring that collected data is securely stored, access is limited to authorized personnel, and retention policies minimize unnecessary data storage.\n",
       "   - Implement data minimization practices to collect only the information necessary for specific purposes and avoid excessive surveillance.\n",
       "\n",
       "6. **Bias Mitigation**:\n",
       "   - Address potential biases in AI algorithms that may disproportionately impact marginalized communities.\n",
       "   - Regularly audit algorithms for bias and accuracy, and implement corrective measures as needed.\n",
       "\n",
       "7. **Public Awareness and Education**:\n",
       "   - Foster public awareness and understanding of AI surveillance technologies, their implications, and individuals' rights regarding these systems.\n",
       "   - Provide educational resources to help citizens understand how surveillance impacts their lives and advocate for their rights.\n",
       "\n",
       "8. **Balancing Safety and Privacy**:\n",
       "   - Develop clear criteria for when and how surveillance is deemed necessary for safety, ensuring it is not overreaching or used as a pretext for invasive monitoring.\n",
       "   - Explore alternative solutions that prioritize safety without compromising privacy, such as community-based safety initiatives or using AI for voluntary opt-in systems.\n",
       "\n",
       "9. **Continuous Evaluation and Adaptation**:\n",
       "   - Establish mechanisms for ongoing evaluation of AI surveillance systems, considering their social impact and effectiveness.\n",
       "   - Be willing to adapt policies and practices based on new findings, technological advancements, or shifts in public sentiment.\n",
       "\n",
       "10. **International and Cross-Jurisdictional Cooperation**:\n",
       "    - Collaborate with international bodies to create uniform standards for AI surveillance that respect human rights across borders.\n",
       "    - Share best practices and lessons learned to improve oversight and accountability globally.\n",
       "\n",
       "By following these steps, we can work towards a balanced approach to deploying AI in surveillance that respects privacy and civil liberties while enhancing safety and security."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Solving the ethical dilemmas presented by the deployment of artificial intelligence (AI) in surveillance requires a thoughtful and multi-faceted approach that balances safety, privacy, and civil liberties. Here's a framework to approach these challenges:\n",
       "\n",
       "**Establish Clear Principles and Guidelines**\n",
       "\n",
       "1. **Develop a Code of Ethics**: Create a code that outlines the acceptable use of AI in surveillance, emphasizing respect for human rights, dignity, and privacy.\n",
       "2. **Define Transparency and Accountability**: Ensure that the public is informed about the deployment of AI in surveillance, including the purpose, scope, and limitations of the technology.\n",
       "3. **Establish Regulatory Frameworks**: Develop and implement regulations that control the use of AI in surveillance, including data protection, usage, and storage guidelines.\n",
       "\n",
       "**Ensure Human Oversight and Review**\n",
       "\n",
       "1. **Implement Human-in-the-Loop**: Design AI systems that allow human reviewers to assess and correct AI-driven decisions, particularly in situations where false positives or negatives could have significant consequences.\n",
       "2. **Regular Audits and Evaluations**: Conduct regular audits and evaluations to ensure AI systems are functioning as intended, and make adjustments as needed to prevent biases or errors.\n",
       "3. **Inclusive and Diverse Review Boards**: Establish review boards comprising diverse stakeholders, including civil liberties experts, technologists, and community representatives, to provide ongoing feedback and guidance.\n",
       "\n",
       "**Mitigate Bias and Error**\n",
       "\n",
       "1. **Data Quality and Validation**: Ensure that training data is diverse, representative, and free from biases, and that AI systems are regularly tested and validated to prevent errors.\n",
       "2. **Fairness and Accountability Metrics**: Develop and apply metrics to measure AI system fairness, accuracy, and accountability, and use these metrics to identify and address potential biases.\n",
       "3. **Continuous Monitoring and Learning**: Continuously monitor AI system performance and update the systems to reflect new insights, ensuring that they remain fair, accurate, and unbiased.\n",
       "\n",
       "**Protect Individual Rights and Freedoms**\n",
       "\n",
       "1. **Data Protection and Anonymization**: Implement robust data protection measures, including anonymization and encryption, to safeguard individual privacy and prevent unauthorized access.\n",
       "2. **Notice and Consent**: Ensure that individuals are informed about the use of AI in surveillance and provide consent for data collection and use.\n",
       "3. **Right to Appeal and Redress**: Establish mechanisms for individuals to appeal AI-driven decisions and seek redress if they believe their rights have been violated.\n",
       "\n",
       "**Foster Public Engagement and Education**\n",
       "\n",
       "1. **Public Awareness Campaigns**: Launch public awareness campaigns to educate citizens about the benefits and risks associated with AI in surveillance.\n",
       "2. **Stakeholder Engagement**: Engage with civil liberties organizations, community groups, and other stakeholders to ensure that their concerns are heard and addressed.\n",
       "3. **Transparency and Explainability**: Provide clear explanations of how AI systems work and make decisions, to foster trust and understanding among the public.\n",
       "\n",
       "**Encourage International Cooperation and Standards**\n",
       "\n",
       "1. **Global Dialogues**: Engage in international discussions to develop shared standards and guidelines for the use of AI in surveillance, respecting human rights and dignity.\n",
       "2. **Cross-Border Collaboration**: Collaborate with other countries to address the global implications of AI in surveillance, including data sharing, protection, and governance.\n",
       "3. **International Frameworks**: Support the development of international frameworks, such as the OECD's AI Principles, to ensure that AI is developed and used responsibly worldwide.\n",
       "\n",
       "By following this framework, we can balance the benefits of AI in surveillance with the need to protect individual rights, safety, and civil liberties, ensuring that these technologies serve the greater good while respecting human dignity and autonomy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Approaching the ethical dilemmas presented by the deployment of artificial intelligence (AI) in surveillance requires a multi-faceted analysis that considers various dimensions, including safety, privacy, and civil liberties. Here's a step-by-step approach to address these concerns:\n",
       "\n",
       "1. Establish clear definitions and boundaries: Define what AI-powered surveillance entails, and identify specific contexts where it is permissible or problematic. Consider the distinction between monitoring for crime prevention vs. excessive intrusion into an individual's private life.\n",
       "2. Assess privacy implications: Investigate potential threats to individuals' right to privacy, such as targeted profiling, predictive policing, and the risks of biased decision-making systems. Develop strategies to mitigate these biases, ensuring fair data collection and interpretation methods.\n",
       "3. Evaluate safety measures: Conduct thorough risk assessments to identify potential safety concerns resulting from AI-powered surveillance, including accidental human harm or increased vigilantism. Implement strict guidelines for system monitoring, alerting procedures, and consequences for misuse.\n",
       "4. Balance individual freedoms against collective security needs: Consider the delicate tension between protecting civil liberties (e.g., free speech, association) and advancing societal interests in safety and security. Foster an ongoing dialogue with citizens to better understand their concerns and concerns and make decisions that respect these trade-offs.\n",
       "5. Implement robust mechanisms for oversight and appeal: Develop a system of internal and external auditors, as well as appeals processes for decision-makers. Allow for scrutiny by third parties or independent review boards to ensure accountability and verify adherence to ethical guidelines.\n",
       "6. Foster transparency and explainability: Prioritize clarity in AI-powered surveillance decisions, allowing users to understand the inputs and algorithms driving those decisions. Develop techniques to facilitate the evaluation of system accountability through transparent data collection practices and unbiased risk assessment models.\n",
       "7. Promote public awareness and understanding: Organize workshops, training programs, and community outreach efforts to inform stakeholders about potential benefits and risks associated with AI-powered surveillance. Utilize digital media to share clear statements on the policy commitments surrounding such systems.\n",
       "8. Develop standards and guidelines for developer accountability: Establish industry-wide practices for the development of responsible and safe AI-powered tools, with a focus on ethics-focused frameworks like FAIR (fairness, accountability, transparency). Implement robust testing protocols in both initial and updated releases.\n",
       "\n",
       "The process involves interlocking considerations:\n",
       "\n",
       "- Assessing and addressing risk factors\n",
       "- Balancing competing values and concerns\n",
       "- Creating mechanisms for ongoing oversight, evaluation, and appeals"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
